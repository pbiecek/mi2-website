# MIÂ² Solutions  {-}

Our team has experience not only in groundbreaking research, but also in deploying these research into business.

We perform champion-challenger evaluations in which we look for potential to increase the effectiveness of predictive models in your company.

We take care of the whole life cycle of the predictive models, from reproducibility of results to constant monitoring and continuous improvement of the model.

We audit models and analyse the sensitivity and vulnerability of the model to incorrect or unexpected behaviours.

We conduct trainings for data-science teams interested in the latest results in the area of responsible predictive modelling. 


## Solutions  {-}

Need support with fairness and XAI analysis of your models? 

Contact us!

## Trainings {-}

#### DALEX for R: Explanation and exploration of machine learning models with R and DALEX {-}

![images/training_xai](images/training_xai.png)

A brief introduction to tools for local and global explanations of predictive models using the DALEX library. The short version is 3 hours, the long version is a 2-day training. During the training you will build several predictive models and take a closer look at how they work.

Find more materials here: https://github.com/pbiecek/XAIatERUM2020


#### Fairmodels: Explaining and Checking Fairness for Predictive Models {-}

![images/training_fairness](images/training_fairness.png)

The tutorial is divided into three parts. First, I talk about fairness in general. Do we have a problem with discrimination, and which areas are affected by it? The second part is related to fairness measures. We  discuss the most common statistics for the detection of discrimination. The third part is the hands-on presentation of software that helps to check and visualize fairness.

Find more materials here: https://github.com/pbiecek/fairness_xkdd_2021




